{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "AA5OuF8mNxLd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AA5OuF8mNxLd",
    "outputId": "68860373-eebc-4cd9-bdca-ac43aa279a17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800c2da-7726-4094-9987-00d7b4192ff8",
   "metadata": {
    "id": "0800c2da-7726-4094-9987-00d7b4192ff8"
   },
   "outputs": [],
   "source": [
    "!pip install openai langchain \"unstructured[all-docs]\"\n",
    "!pip install pinecone-client langchain-experimental langchain-pinecone langchain-openai\n",
    "!pip install langchain-core\n",
    "!pip install langchainhub\n",
    "!pip install chromadb\n",
    "!pip install PyPDF2\n",
    "!pip install PyMuPDF\n",
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699782a4-8622-40ea-9c86-f1cce9313c29",
   "metadata": {
    "id": "699782a4-8622-40ea-9c86-f1cce9313c29"
   },
   "outputs": [],
   "source": [
    "!apt-get install poppler-utils\n",
    "!apt-get install tesseract-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b4d20e-e7f9-4c4f-bd3c-eada6f24eab0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2b4d20e-e7f9-4c4f-bd3c-eada6f24eab0",
    "outputId": "e44370be-09c7-4853-9d61-6e9fb82e78a8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import chromadb\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from tqdm import tqdm\n",
    "import base64\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "# from unstructured.partition.pdf import partition_pdf\n",
    "from typing import List, Tuple\n",
    "# import cv2.typing\n",
    "# from PyPDF2 import PdfReader, PdfWriter\n",
    "# import fitz\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gRB_c6mgRPTa",
   "metadata": {
    "id": "gRB_c6mgRPTa"
   },
   "outputs": [],
   "source": [
    "embedding_fn = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2748b8-829e-47d5-bdda-1c8e13f1e0e6",
   "metadata": {
    "id": "ea2748b8-829e-47d5-bdda-1c8e13f1e0e6"
   },
   "source": [
    "## Piazza Posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d076492e-ee58-46d7-835b-e92c6c08c36e",
   "metadata": {
    "id": "d076492e-ee58-46d7-835b-e92c6c08c36e"
   },
   "outputs": [],
   "source": [
    "def concatenate_posts(data):\n",
    "    posts = []\n",
    "    for post in data[\"response\"]:\n",
    "        final_string = \"\"\n",
    "        final_string += \"Post Subject: \" + post[\"value\"][\"subject\"] + \"\\nPost Content: \" + post[\"value\"][\"content\"] + \"\\nFollow Up Discussion: \"\n",
    "        for follow_up in post[\"value\"][\"follow_ups\"]:\n",
    "            final_string += follow_up[\"subject\"] + \" \" + follow_up[\"content\"] + \" \"\n",
    "        posts.append(final_string)\n",
    "    return posts\n",
    "\n",
    "def load_documents(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    hw_posts = concatenate_posts(data)\n",
    "    hw_docs = [Document(x) for x in hw_posts]\n",
    "    return hw_docs\n",
    "\n",
    "def create_faiss_index(docs, embedding_fn, pd):\n",
    "    db = FAISS.from_documents(docs, embedding_fn)\n",
    "    db.save_local(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ccd262-fa07-458b-ae13-6f3fff95cfff",
   "metadata": {
    "id": "05ccd262-fa07-458b-ae13-6f3fff95cfff",
    "outputId": "516f79d7-3f9b-4eec-8aca-877e8893cb5a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "piazza_path = \"./data/piazza/\"\n",
    "vectordb_path = \"./data/vector_index/\"\n",
    "for fn in tqdm(os.listdir(piazza_path)):\n",
    "    name = fn.split('.')[0]\n",
    "    _format = fn.split('.')[1]\n",
    "    if _format != \"json\":\n",
    "        continue\n",
    "    pd = vectordb_path + name + \"_db\"\n",
    "    hw_docs = load_documents(piazza_path+fn)\n",
    "    create_faiss_index(hw_docs, embedding_fn, pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4070a15-9285-4930-9469-820d0fcee39e",
   "metadata": {
    "id": "f4070a15-9285-4930-9469-820d0fcee39e"
   },
   "source": [
    "## PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43828978-e027-4c97-8ceb-a311bce6067f",
   "metadata": {
    "id": "43828978-e027-4c97-8ceb-a311bce6067f"
   },
   "outputs": [],
   "source": [
    "def extract_pdf_data(fpath) -> List:\n",
    "    \"\"\"\n",
    "    Extract text, and tables from PDF\n",
    "    :param fpath: filepath to the PDF\n",
    "    :return: List of raw data\n",
    "    \"\"\"\n",
    "    return partition_pdf(\n",
    "        filename=fpath,\n",
    "        strategy=\"hi_res\",\n",
    "        extract_images_in_pdf=False,\n",
    "        extract_image_block_output_dir=\"temp\",\n",
    "        infer_table_structure=False,\n",
    "        chunking_strategy=\"basic\",\n",
    "        max_characters=5000,\n",
    "    )\n",
    "\n",
    "def get_elements(raw_data) -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Extract text, and tables str elements\n",
    "    :param raw_data: List of raw data\n",
    "    :return: List of text and table elements\n",
    "    \"\"\"\n",
    "    texts = []\n",
    "    for element in raw_data:\n",
    "      if \"unstructured.documents.elements.CompositeElement\" in str(type(element)):\n",
    "        texts.append(str(element))\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4f4e4067-6cf9-4c97-ab84-ac3a5d39e350",
   "metadata": {
    "id": "4f4e4067-6cf9-4c97-ab84-ac3a5d39e350"
   },
   "outputs": [],
   "source": [
    "def process_pdfs(input_dir, output_dir, output_image_dir):\n",
    "    # Iterate through PDF files in input directory\n",
    "    pdf_docs = []\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith('.pdf'):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, f\"{filename[:-4]}_pages\")\n",
    "            output_image_dir_path = os.path.join(output_image_dir, f\"{filename[:-4]}_pages\")\n",
    "            os.makedirs(output_path, exist_ok=True)\n",
    "            os.makedirs(output_image_dir_path, exist_ok=True)\n",
    "\n",
    "            # Read PDF file\n",
    "            img_index = 0\n",
    "            with open(input_path, 'rb') as file:\n",
    "                pdf_reader = PdfReader(file)\n",
    "                num_pages = len(pdf_reader.pages)\n",
    "                pdf_path = input_path.replace(\"/content/drive/My Drive/\", \"./data/\")\n",
    "                # Iterate through each page of the PDF\n",
    "                for page_num in tqdm(range(num_pages)):\n",
    "                    page = pdf_reader.pages[page_num]\n",
    "                    output_page_path = os.path.join(output_path, f\"{page_num+1}.pdf\")\n",
    "\n",
    "                    # Write current page to separate PDF file\n",
    "                    with open(output_page_path, 'wb') as output_file:\n",
    "                        pdf_writer = PdfWriter()\n",
    "                        pdf_writer.add_page(page)\n",
    "                        pdf_writer.write(output_file)\n",
    "\n",
    "\n",
    "                    # iterate each page and name the loc as fpath\n",
    "                    raw_data = extract_pdf_data(output_page_path)\n",
    "                    texts = get_elements(raw_data)\n",
    "\n",
    "                    pdf_document = fitz.open(output_page_path)\n",
    "\n",
    "                    page = pdf_document.load_page(0)\n",
    "                    image_list = page.get_images(full=True)\n",
    "                    if len(image_list) == 0:\n",
    "                      pdf_docs.append(Document(page_content=texts[0], metadata=dict(pdf=pdf_path, pdf_page_num=page_num+1)))\n",
    "                      continue\n",
    "\n",
    "                    img_info = image_list[0]\n",
    "                    xref = img_info[0]\n",
    "                    base_image = pdf_document.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    image_ext = base_image[\"ext\"]\n",
    "\n",
    "                    # Save the image to the output directory\n",
    "                    image_path = os.path.join(output_image_dir_path, f\"img_{img_index+1}.jpg\")\n",
    "                    with open(image_path, \"wb\") as image_file:\n",
    "                        image_file.write(image_bytes)\n",
    "                    img_index += 1\n",
    "                    image_path = image_path.replace(\"./\", \"./data/\")\n",
    "\n",
    "\n",
    "                    # save text chunk along with image, page_num, and pdf name as metadata in the vectordb\n",
    "                    pdf_docs.append(Document(page_content=texts[0], metadata=dict(image_path=image_path, pdf=pdf_path, pdf_page_num=page_num+1)))\n",
    "\n",
    "    return pdf_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f876b29-ca74-4d76-9c03-a1bb922558e4",
   "metadata": {
    "id": "4f876b29-ca74-4d76-9c03-a1bb922558e4"
   },
   "outputs": [],
   "source": [
    "input_directory = \"/content/drive/My Drive/Lectures\"\n",
    "output_directory = \"./output\"\n",
    "output_image_dir = \"./images\"\n",
    "pdf_docs = process_pdfs(input_directory, output_directory, output_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "XOh4l7pVqOfS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XOh4l7pVqOfS",
    "outputId": "c9dd5305-964e-40bc-9a90-4c9c2dd38f07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='16/30\\n\\nIntroduction', metadata={'image_path': './data/images/585_1_pages/img_1.jpg', 'pdf': './data/Lectures/585_1.pdf', 'pdf_page_num': 1})]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c19e4366-8bd2-4946-9495-32d760f01d64",
   "metadata": {
    "id": "c19e4366-8bd2-4946-9495-32d760f01d64"
   },
   "outputs": [],
   "source": [
    "vectordb_path = \"./data/vector_index/\"\n",
    "pd = vectordb_path + \"pdf\" + \"_db\"\n",
    "os.makedirs(pd, exist_ok=True)\n",
    "create_faiss_index(pdf_docs, embedding_fn, pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VBiQL2AetcPx",
   "metadata": {
    "id": "VBiQL2AetcPx"
   },
   "outputs": [],
   "source": [
    "!cp -r ./images /content/drive/My\\ Drive/ta_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0yMngaSVub7t",
   "metadata": {
    "id": "0yMngaSVub7t"
   },
   "outputs": [],
   "source": [
    "!cp -r ./data/vector_index /content/drive/My\\ Drive/ta_vector_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdf82fb-eb18-4712-b702-8ab5e94f8016",
   "metadata": {},
   "source": [
    "## Video (OCR+Transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd665487-0eb3-4588-9dac-259c66386870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_frames(data, filepath):\n",
    "    frames = []\n",
    "    image_path = \"./data/Video/images/\"+filepath.split('/')[-1].split('.')[0]+'/'\n",
    "    for frame in data:\n",
    "        final_string = \"\"\n",
    "        final_string += \"Frame Text: \" + frame[\"OCR_text\"] + \"\\nTranscription: \" + frame[\"audio_transcription\"]\n",
    "        metadata=dict(image_path=image_path+frame[\"frame\"], video=frame[\"link\"])\n",
    "        frames.append((final_string, metadata))\n",
    "        \n",
    "    return frames\n",
    "\n",
    "def load_documents(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    video_frames = concatenate_frames(data, filepath)\n",
    "    video_docs = [Document(page_content=x, metadata=y) for x, y in video_frames]\n",
    "    return video_docs\n",
    "\n",
    "def create_faiss_index(docs, embedding_fn, pd):\n",
    "    db = FAISS.from_documents(docs, embedding_fn)\n",
    "    db.save_local(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ce7ced2-a1e8-418d-b22a-fcc0342cc3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "video_path = \"./data/Video/\"\n",
    "vectordb_path = \"./data/video_index/\"\n",
    "for fn in tqdm(os.listdir(video_path)):\n",
    "    if \"json\" not in fn:\n",
    "        continue\n",
    "    name = fn.split('.')[0]\n",
    "    _format = fn.split('.')[1]\n",
    "    if _format != \"json\":\n",
    "        continue\n",
    "    pd = vectordb_path + name + \"_db\"\n",
    "    video_docs = load_documents(video_path+fn)\n",
    "    create_faiss_index(video_docs, embedding_fn, pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c3475dd-be9f-4ff5-adab-a84f9b21b802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Frame Text: di\\n\\nKrishnan Luhar\\n\\nTranscription: all right 5:00 hi everyone 107 participants', metadata={'image_path': './data/Video/images/Lec_2/output_frame_0001.jpg', 'video': 'https://youtu.be/oNDOzpIiVEM?t=0h0m0s'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4672023-84d1-4de9-bcb2-f891789f7805",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ta",
   "language": "python",
   "name": "ta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
